{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVNJQPYo9JU8",
        "outputId": "b391353e-2f87-4135-cf15-5b2a16e7111a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 7.0 kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0\n",
            "ERROR: unknown command \"transformers==3.1.0\"\n",
            "Collecting adapter-transformers==1.1.1\n",
            "  Downloading adapter_transformers-1.1.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 7.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.3\n",
            "  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==1.1.1) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==1.1.1) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==1.1.1) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==1.1.1) (3.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==1.1.1) (3.17.3)\n",
            "Collecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==1.1.1) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from adapter-transformers==1.1.1) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->adapter-transformers==1.1.1) (3.0.7)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->adapter-transformers==1.1.1) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==1.1.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==1.1.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==1.1.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers==1.1.1) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==1.1.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers==1.1.1) (1.1.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, adapter-transformers\n",
            "Successfully installed adapter-transformers-1.1.1 sacremoses-0.0.49 sentencepiece-0.1.91 tokenizers-0.9.3\n"
          ]
        }
      ],
      "source": [
        "# adapter-transformers library is based on torch==1.4.0 and transformers==3.1.0.\n",
        "!pip install torch==1.4.0\n",
        "!pip transformers==3.1.0\n",
        "!pip install adapter-transformers==1.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dBkvK8qF0uu"
      },
      "source": [
        "## Import required Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJuQa7eoyt2U"
      },
      "outputs": [],
      "source": [
        "import torch, os\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import RobertaConfig, RobertaModelWithHeads, RobertaTokenizer, AdapterType, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKMVNtTvGKmw"
      },
      "source": [
        "## Set seed of randomization and working device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st54LckLtikU",
        "outputId": "0107ff06-dc80-4639-e26f-7e0fc29843ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(device)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    # Set the random seed\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_T0HnAjHID-"
      },
      "source": [
        "### Define data generator class and preparation function.\n",
        "\n",
        "The custom dataset should inherit [`Dataset`](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class) and define the following methods:\n",
        "  * `__len__` so that len(dataset) returns the size of the dataset.\n",
        "  * `__getitem__` to support the indexing such that `dataset[i]` can be used to get $i$th sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM1Nuy0-zE5m"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    # initialization\n",
        "    def __init__(self, dataframe, tokenizer, max_len, lab2ind):\n",
        "        \"\"\"\n",
        "          dataframe: pandas DataFrame.\n",
        "          tokenizer: Hugginfance BERT/RoBERTa tokenizer\n",
        "          max_len: maximal length of input sequence\n",
        "          lab2ind: dictionary of label classes\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.comment_text = self.data.content\n",
        "        self.labels = self.data.label\n",
        "        self.max_len = max_len\n",
        "        self.lab2ind = lab2ind\n",
        "\n",
        "    # get the size of the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    # generate sample by index\n",
        "    def __getitem__(self, index):\n",
        "        # get ith sample and label\n",
        "        comment_text = str(self.comment_text[index])\n",
        "        label = str(self.labels[index])\n",
        "\n",
        "        label = self.lab2ind[label]\n",
        "        # use encode_plus() of Transformers to tokenize and vectorize input seuqnce and covert it to tensors. \n",
        "        # this method truncate or pad sequence to the maximal length and then return pytorch tensors. \n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors = \"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'ids': inputs['input_ids'],\n",
        "            'mask': inputs['attention_mask'],\n",
        "            'targets': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgAYmEtjNklX"
      },
      "source": [
        "### Define a function to load datasets and create data iterators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKUn3JhzNdb_"
      },
      "outputs": [],
      "source": [
        "def regular_encode(file_path, tokenizer, lab2ind, shuffle=True, num_workers = 2, batch_size=64, maxlen = 32, mode = 'train'): \n",
        "    '''\n",
        "      file_path: path to your dataset file\n",
        "      tokenizer: tokenizer method\n",
        "      lab2ind: label-to-index dictionary\n",
        "      shuffle: shuffle the dataset or not\n",
        "      num_workers: a number of data processors\n",
        "      batch_size: the number of batch size\n",
        "      maxlen: maximal sequence length\n",
        "      mode: the type of dataset\n",
        "    '''\n",
        "    # if we are in train mode, we will load two columns (i.e., text and label).\n",
        "    if mode == 'train':\n",
        "        # Use pandas to load dataset, the dataset should be a tsv file where the first line is the header.\n",
        "        df = pd.read_csv(file_path, delimiter='\\t',header=0, names=['content','label'], encoding='utf-8', quotechar=None, quoting=3)\n",
        "    \n",
        "    # if we are in predict mode, we will load one column (i.e., text).\n",
        "    elif mode == 'predict':\n",
        "        df = pd.read_csv(file_path, delimiter='\\t',header=0, names=['content', 'label'])\n",
        "    else:\n",
        "        print(\"the type of mode should be either 'train' or 'predict'. \")\n",
        "        return\n",
        "        \n",
        "    print(\"{} Dataset: {}\".format(file_path, df.shape))\n",
        "    # instantiate the dataset instance \n",
        "    custom_set = CustomDataset(df, tokenizer, maxlen,lab2ind)\n",
        "    \n",
        "    dataset_params = {'batch_size': batch_size, 'shuffle': shuffle, 'num_workers': num_workers}\n",
        "\n",
        "    batch_data_loader = DataLoader(custom_set, **dataset_params)\n",
        "    # return a data iterator\n",
        "    return batch_data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgBDJUSYORlw"
      },
      "source": [
        "### Training and evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKKJ1AJtOQi2"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, scheduler, criterion):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    for _, batch in enumerate(iterator):\n",
        "        # load data batch\n",
        "        input_ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        input_mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        labels = batch['targets'].to(device, dtype = torch.long)\n",
        "        # forward\n",
        "        outputs = model(input_ids, input_mask, labels=labels)\n",
        "        loss, logits = outputs[:2]\n",
        "        \n",
        "        # delete used variables to free GPU memory\n",
        "        del batch, input_ids, input_mask, labels\n",
        "        optimizer.zero_grad()\n",
        "        # backward\n",
        "        if torch.cuda.device_count() == 1:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            epoch_loss += loss.cpu().item()\n",
        "        else:\n",
        "            loss.mean().backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            epoch_loss += loss.mean().cpu().item()\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    \n",
        "    # free GPU memory\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, batch in enumerate(iterator, 0):\n",
        "        # Add batch to GPU\n",
        "            input_ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            input_mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            labels = batch['targets'].to(device, dtype = torch.long)\n",
        "            # forward\n",
        "            outputs = model(input_ids, input_mask, labels=labels)\n",
        "            loss, logits = outputs[:2]\n",
        "\n",
        "            # delete used variables to free GPU memory\n",
        "            del batch, input_ids, input_mask\n",
        "\n",
        "            if torch.cuda.device_count() == 1:\n",
        "                epoch_loss += loss.cpu().item()\n",
        "            else:\n",
        "                epoch_loss += loss.sum().cpu().item()\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(logits.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "            all_pred.extend(predicted)\n",
        "            all_label.extend(labels.cpu())\n",
        "    # computing metrics \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    recall = recall_score(all_label, all_pred, average='macro')\n",
        "    precision = precision_score(all_label, all_pred, average='macro')\n",
        "\n",
        "    return epoch_loss/len(iterator), accuracy, f1score, recall, precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iFQAgsrOZTD"
      },
      "source": [
        "### Create a optimizer and scheduler.\n",
        "\n",
        "The model train with a linear learing rate [scheduler](https://huggingface.co/transformers/main_classes/optimizer_schedules.html#transformers.get_linear_schedule_with_warmup) that decreases linearly from the peak learning rate to 0 after a warmup period where learning rate linearly increase from 0 to the peak learning rate. \n",
        "\n",
        "![](https://huggingface.co/transformers/_images/warmup_linear_schedule.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "povIm1kmOZkZ"
      },
      "outputs": [],
      "source": [
        "def create_optimizer_and_scheduler(model, num_training_steps, warmup_steps, learning_rate):\n",
        "    \"\"\"\n",
        "    Setup the optimizer and the learning rate scheduler.\n",
        "    num_training_steps: the number of training steps\n",
        "    warmup_steps: the number of warm-up steps\n",
        "    learning_rate: the peak learning rate\n",
        "    \"\"\"\n",
        "    optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate\n",
        "    )\n",
        "    \n",
        "    lr_scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps=warmup_steps, \n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "\n",
        "    return optimizer, lr_scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OnHWgBdJvC6"
      },
      "source": [
        "### Train Adapter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHgthNPNPlck"
      },
      "source": [
        "Load model and tokenizer of `RoBERTa-Base` by the shortcut name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "f75b76c90b9340e3ab358309a09509ce",
            "2a29b08ed963420da58f4f43bf29c725",
            "545ad30e07964a5faa0044d9f7e46f03",
            "39287b808e1445ffb27dc381739bb7e6",
            "74b11c75724144f9854b18f97ec8d14e",
            "529d03c8b42d463b9fda53c87174ed68",
            "ae57f2acd3fb49fdadec06a3c54860c9",
            "83d1e6235a9b49e5a2bab1d378834f68",
            "67df93aed741441f8a88add0639b710d",
            "ad40fa9839d24af9a4aba1b83471086d",
            "3a1e84513ed74bb3be7c3b6009f9a821",
            "670ee76c0e0e451a9bc2befbb6fb1604",
            "cd62d6ab0f6d45189c6fc19d1936057a",
            "0e149d28303b483280df566a65af767f",
            "eaad61d60ce2403e8e57b0539d31edc8",
            "5403dfa06353421e8f46b7d76b77da81",
            "0d64f13c4fa54e83b51950ee94014e25",
            "4937e121b2364fd0b13291cce36df554",
            "8a6ea42ecd324afd89d1407833779e20",
            "6db85b01123e44af93087ab73abe3e84",
            "4783d0f3ba7e41e39cb4045bfddcfbca",
            "57f47eb280904a90ad15605e068e2945",
            "558fa0b563674693a1fc752dd9980448",
            "c2bec351358c4d88ac54e65bd5e6e9ec",
            "9bb1cc49cfa24db4bbccf61e90f2ee04",
            "6c517bb6914b41a1a0fdb66296e4e043",
            "1f0b6e3c82644aafa8a7e9fae28b8a72",
            "50a6d2db37f14f16951dc35f32be8104",
            "46ae277f49ca4b5bbe2e1b47eb7140a0",
            "ad00968e696f4384ace0927f0ba9aa86",
            "52299a8bbe1545458a468a74b212429d",
            "a96e9e2ce9de4803a292a82c64589061",
            "e9924f658ba64ad9be445a70d105e907",
            "5d00222438294f619173b5e59da98c63",
            "3468bfb934df4abbacf6956eaf8e00cc",
            "2200e32ea9564ce3bef0465d89684fae",
            "8af6644116da4d22872c69bdd641ae56",
            "3e5e41bd17b04f499765ce4f5a7119dd",
            "e7f3b24ed052450398944309e91c2cec",
            "30c17a76381c4b7fb51afe106559cb00",
            "3159e1eca56842b59158bcb0cc7e7909",
            "45711ca485524c85abc75439eb5a2412",
            "f626a3d3db2c412789caecbe90032af7",
            "c6015fae6185428d8e9147d1109d1c4f"
          ]
        },
        "id": "uKZk5Ctd1xF8",
        "outputId": "62e51910-5327-4175-a2e6-7797de986ff3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f75b76c90b9340e3ab358309a09509ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "670ee76c0e0e451a9bc2befbb6fb1604"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "558fa0b563674693a1fc752dd9980448"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d00222438294f619173b5e59da98c63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_name = \"roberta-base\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "model = RobertaModelWithHeads.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63utOxW56H99",
        "outputId": "6abcbbfb-0e21-47fa-bc30-f80bbd884b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The roberta-base has 124,645,632 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The roberta-base has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6mnmERrP2Il"
      },
      "source": [
        "Add task-specific adapter module for sociality classification task that is a single text classification task. By calling `train_adapter([\"social\"])`, we freeze all transformer parameters and only optimize the parameters of `social` adapter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqFygAltPhub"
      },
      "outputs": [],
      "source": [
        "model.add_adapter(\"social\", AdapterType.text_task)\n",
        "model.train_adapter([\"social\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJp-Sz8VQDNl"
      },
      "source": [
        "Add the classification head, i.e., a two-layer feed-forward neural network, on top of the Transformer layers. \n",
        "\n",
        "The method `model.set_active_adapters([[\"social\"]])` registers the `social` adapter as a default for training. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqGjybRjee98"
      },
      "outputs": [],
      "source": [
        "model.add_classification_head(\"social\", num_labels=2)\n",
        "model.set_active_adapters([[\"social\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdBm0YSi4MnW"
      },
      "source": [
        "Send model to device (CPU/GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM9ND0jdlAN_"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CbM0uPSKXV2",
        "outputId": "eefb0928-05a1-4894-bd14-e45c530aa620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RobertaModelWithHeads(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (attention_text_task_adapters): ModuleDict()\n",
            "              (adapter_fusion_layer): ModuleDict()\n",
            "              (attention_text_lang_adapters): ModuleDict()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (adapter_fusion_layer): ModuleDict()\n",
            "            (layer_text_task_adapters): ModuleDict(\n",
            "              (social): Adapter(\n",
            "                (non_linearity): Activation_Function_Class()\n",
            "                (adapter_down): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "                  (1): Activation_Function_Class()\n",
            "                )\n",
            "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "            (layer_text_lang_adapters): ModuleDict()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "    (invertible_lang_adapters): ModuleDict()\n",
            "  )\n",
            "  (heads): ModuleDict(\n",
            "    (social): ClassificationHead(\n",
            "      (0): Dropout(p=0.1, inplace=False)\n",
            "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (2): Activation_Function_Class()\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R6LSkZbQoTj",
        "outputId": "11b14c2c-a76f-4f1f-c221-503d91a7bf18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The social adapter RoBERTa model has 1,486,658 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "print(f'The social adapter RoBERTa model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZyBV1Sg6l2b"
      },
      "source": [
        "The number of trainable parameters decrease significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPiPgEj66xyH"
      },
      "source": [
        "### Training\n",
        "\n",
        "Specify hyper-parameters and load datasets.\n",
        "\n",
        "We freeze all the Transformer layers and only optimize the parameters of adapter modules that are new added and randomly initialized. Hence, we use large learning rate (i.e., 3e-4)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh1RIyhsphYc",
        "outputId": "4a23f088-afea-4974-91e4-d19b8300cecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"/content/drive/MyDrive/585data/train.csv\", delimiter=\";\")\n",
        "train_data = train_data[[\"text\", \"account.type\"]]\n",
        "train_data.to_csv(\"/content/drive/MyDrive/585data/train.tsv\", sep=\"\\t\", encoding=\"utf-8\", index=False)"
      ],
      "metadata": {
        "id": "mdBS52mCppc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_data = pd.read_csv(\"/content/drive/MyDrive/585data/validation.csv\", delimiter=\";\")\n",
        "dev_data = train_data[[\"text\", \"account.type\"]]\n",
        "dev_data.to_csv(\"/content/drive/MyDrive/585data/dev.tsv\", sep=\"\\t\", encoding=\"utf-8\", index=False)"
      ],
      "metadata": {
        "id": "EnmPLVJrrNuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"/content/drive/MyDrive/585data/test.csv\", delimiter=\";\")\n",
        "test_data = train_data[[\"text\", \"account.type\"]]\n",
        "test_data.to_csv(\"/content/drive/MyDrive/585data/test.tsv\", sep=\"\\t\", encoding=\"utf-8\", index=False)"
      ],
      "metadata": {
        "id": "vuDfiTs8rTvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ-zE5YmoNy7"
      },
      "outputs": [],
      "source": [
        "lab2ind = {'human': 0, 'bot': 1}\n",
        "batch_size = 32\n",
        "max_seq_length = 32\n",
        "num_epochs = 5\n",
        "warmup_proportion = 0.1\n",
        "learning_rate = 3e-4\n",
        "max_grad_norm = 1.0\n",
        "data_dir = \"/content/drive/MyDrive/585data/\"\n",
        "\n",
        "train_file = os.path.join(data_dir, \"train.tsv\")\n",
        "dev_file = os.path.join(data_dir, \"dev.tsv\")\n",
        "test_file = os.path.join(data_dir, \"test.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Dw-Ewa76Pm"
      },
      "source": [
        "Create data interators. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Arw0qqhqmKzn",
        "outputId": "4eef56c8-3788-47fc-e2d2-90205219ac15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/585data/train.tsv Dataset: (22590, 2)\n",
            "/content/drive/MyDrive/585data/dev.tsv Dataset: (22590, 2)\n",
            "/content/drive/MyDrive/585data/test.tsv Dataset: (22590, 2)\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = regular_encode(train_file, tokenizer, lab2ind, shuffle=True, batch_size=batch_size, maxlen = max_seq_length)\n",
        "validation_dataloader = regular_encode(dev_file, tokenizer, lab2ind, shuffle=False, batch_size=batch_size, maxlen = max_seq_length)\n",
        "test_dataloader = regular_encode(test_file, tokenizer, lab2ind, shuffle=False, batch_size=batch_size, maxlen = max_seq_length)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMpFRRvN7-pJ"
      },
      "source": [
        "Optimizer, sheduler, and loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LI1eJRN6pH1l"
      },
      "outputs": [],
      "source": [
        "num_training_steps\t= len(train_dataloader) * num_epochs\n",
        "num_warmup_steps = num_training_steps * warmup_proportion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skOVX76SqU0I"
      },
      "outputs": [],
      "source": [
        "optimizer, scheduler = create_optimizer_and_scheduler(model, num_training_steps, num_warmup_steps, learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QZR9g0T8LBD"
      },
      "source": [
        "Train the model with 10 epochs. The training speed is much faster than fully fine-tuning (i.e., optimize the parameters of the entire RoBERTa). We save the `social` adapter module at the end of each epoach rather than the entire RoBERTa model. This `social` adapter is light weight: it is only 3MB! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "GmHkqZquq-FO",
        "outputId": "bf72f0fc-4d76-4647-fb21-242f465236ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-f52bdcffd8f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-ef4f79b9ec5c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, scheduler, criterion)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# load data batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-4-f05ace368dbb>\", line 27, in __getitem__\n    label = self.lab2ind[label]\nKeyError: 'nan'\n"
          ]
        }
      ],
      "source": [
        "epoch_res = []\n",
        "\n",
        "for epoch in trange(num_epochs, desc=\"Epoch\"):\n",
        "    train_loss = train(model, train_dataloader, optimizer, scheduler, criterion)\t  \n",
        "    val_loss, val_acc, val_f1, val_recall, val_precision = evaluate(model, validation_dataloader, criterion)\n",
        "\n",
        "    epoch_eval_result = {\"epoch_num\":int(epoch + 1),\"train_loss\":train_loss,\n",
        "                      \"val_acc\":val_acc, \"val_recall\":val_recall, \"val_precision\":val_precision, \"val_f1\":val_f1\n",
        "                      }\n",
        "    print(epoch_eval_result)\n",
        "    epoch_res.append(epoch_eval_result)\n",
        "    save_path = \"./epoch\"+str(epoch+1) \n",
        "    if os.path.exists(save_path) == False:\n",
        "      os.makedirs(save_path)\n",
        "\n",
        "    model.save_all_adapters(save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQqG5JOd8oFF"
      },
      "source": [
        "Present the validation preformance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "8cah3xlmrWen",
        "outputId": "7c6c1740-f497-4dbe-cb21-2cc703561228"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch_num</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.132116</td>\n",
              "      <td>0.941288</td>\n",
              "      <td>0.943161</td>\n",
              "      <td>0.939930</td>\n",
              "      <td>0.940966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.119514</td>\n",
              "      <td>0.938447</td>\n",
              "      <td>0.940198</td>\n",
              "      <td>0.937072</td>\n",
              "      <td>0.938101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.110955</td>\n",
              "      <td>0.938447</td>\n",
              "      <td>0.940198</td>\n",
              "      <td>0.937072</td>\n",
              "      <td>0.938101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.110976</td>\n",
              "      <td>0.938447</td>\n",
              "      <td>0.940198</td>\n",
              "      <td>0.937072</td>\n",
              "      <td>0.938101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.145735</td>\n",
              "      <td>0.936553</td>\n",
              "      <td>0.938286</td>\n",
              "      <td>0.935173</td>\n",
              "      <td>0.936196</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch_num  train_loss   val_acc  val_recall  val_precision    val_f1\n",
              "1          2    0.132116  0.941288    0.943161       0.939930  0.940966\n",
              "2          3    0.119514  0.938447    0.940198       0.937072  0.938101\n",
              "3          4    0.110955  0.938447    0.940198       0.937072  0.938101\n",
              "4          5    0.110976  0.938447    0.940198       0.937072  0.938101\n",
              "0          1    0.145735  0.936553    0.938286       0.935173  0.936196"
            ]
          },
          "execution_count": 36,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "report_df = pd.DataFrame(epoch_res)\n",
        "report_df.sort_values(by=[\"val_f1\"], ascending=False, inplace=True)\n",
        "report_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVSTo5cpJ1-Q"
      },
      "source": [
        "### Load the best adapter model and evaluate on Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJNvbRHi8_AH"
      },
      "source": [
        "Load the pre-trained RoBERTa model by shortcut name. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh3Sath22S4L",
        "outputId": "0bf6ce7d-95f5-4151-f6fe-688b22ddf504"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"roberta-base\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "model = RobertaModelWithHeads.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ysokZo4Q9UC"
      },
      "source": [
        "Load the trained task-specific adapter module that achieves the best performance on validation set.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBe8hu6kDiLr",
        "outputId": "40a90745-d0fe-427e-cf00-3e16714a6b1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overwriting existing adapter 'social'.\n",
            "Overwriting existing head 'social'\n"
          ]
        }
      ],
      "source": [
        "adapter_name = model.load_adapter(\"./epoch2/social\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjalnhFTCah-"
      },
      "source": [
        "Add the trained adapter to RoBERTa and evaluate on test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtNwttliDqkA"
      },
      "outputs": [],
      "source": [
        "model.set_active_adapters(adapter_name)\n",
        "model = model.to(device)\n",
        "test_loss, test_acc, test_f1, test_recall, test_precision = evaluate(model, test_dataloader, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAWfJ-AoD1Ch",
        "outputId": "e28cefc1-108c-4216-fd1a-7b74cdc00d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2498893676833673 0.9204545454545454 0.9199480181936321 0.9219626778024272 0.918901412100013\n"
          ]
        }
      ],
      "source": [
        "print(test_loss, test_acc, test_f1, test_recall, test_precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiF6PiRSDItt"
      },
      "source": [
        "### References:\n",
        "* Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., ... & Gelly, S. (2019, May). [Parameter-efficient transfer learning for NLP](http://proceedings.mlr.press/v97/houlsby19a/houlsby19a.pdf). In International Conference on Machine Learning (pp. 2790-2799). PMLR.\n",
        "\n",
        "* https://docs.adapterhub.ml/index.html\n",
        "\n",
        "* https://medium.com/dair-ai/adapters-a-compact-and-extensible-transfer-learning-method-for-nlp-6d18c2399f62\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpXZOuUUDTmq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RoBERTa_Adapter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f75b76c90b9340e3ab358309a09509ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a29b08ed963420da58f4f43bf29c725",
              "IPY_MODEL_545ad30e07964a5faa0044d9f7e46f03",
              "IPY_MODEL_39287b808e1445ffb27dc381739bb7e6"
            ],
            "layout": "IPY_MODEL_74b11c75724144f9854b18f97ec8d14e"
          }
        },
        "2a29b08ed963420da58f4f43bf29c725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_529d03c8b42d463b9fda53c87174ed68",
            "placeholder": "​",
            "style": "IPY_MODEL_ae57f2acd3fb49fdadec06a3c54860c9",
            "value": "Downloading: 100%"
          }
        },
        "545ad30e07964a5faa0044d9f7e46f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83d1e6235a9b49e5a2bab1d378834f68",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67df93aed741441f8a88add0639b710d",
            "value": 898823
          }
        },
        "39287b808e1445ffb27dc381739bb7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad40fa9839d24af9a4aba1b83471086d",
            "placeholder": "​",
            "style": "IPY_MODEL_3a1e84513ed74bb3be7c3b6009f9a821",
            "value": " 899k/899k [00:00&lt;00:00, 2.87MB/s]"
          }
        },
        "74b11c75724144f9854b18f97ec8d14e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529d03c8b42d463b9fda53c87174ed68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae57f2acd3fb49fdadec06a3c54860c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83d1e6235a9b49e5a2bab1d378834f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67df93aed741441f8a88add0639b710d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad40fa9839d24af9a4aba1b83471086d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a1e84513ed74bb3be7c3b6009f9a821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "670ee76c0e0e451a9bc2befbb6fb1604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd62d6ab0f6d45189c6fc19d1936057a",
              "IPY_MODEL_0e149d28303b483280df566a65af767f",
              "IPY_MODEL_eaad61d60ce2403e8e57b0539d31edc8"
            ],
            "layout": "IPY_MODEL_5403dfa06353421e8f46b7d76b77da81"
          }
        },
        "cd62d6ab0f6d45189c6fc19d1936057a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d64f13c4fa54e83b51950ee94014e25",
            "placeholder": "​",
            "style": "IPY_MODEL_4937e121b2364fd0b13291cce36df554",
            "value": "Downloading: 100%"
          }
        },
        "0e149d28303b483280df566a65af767f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a6ea42ecd324afd89d1407833779e20",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6db85b01123e44af93087ab73abe3e84",
            "value": 456318
          }
        },
        "eaad61d60ce2403e8e57b0539d31edc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4783d0f3ba7e41e39cb4045bfddcfbca",
            "placeholder": "​",
            "style": "IPY_MODEL_57f47eb280904a90ad15605e068e2945",
            "value": " 456k/456k [00:00&lt;00:00, 1.01MB/s]"
          }
        },
        "5403dfa06353421e8f46b7d76b77da81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d64f13c4fa54e83b51950ee94014e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4937e121b2364fd0b13291cce36df554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a6ea42ecd324afd89d1407833779e20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6db85b01123e44af93087ab73abe3e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4783d0f3ba7e41e39cb4045bfddcfbca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57f47eb280904a90ad15605e068e2945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "558fa0b563674693a1fc752dd9980448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2bec351358c4d88ac54e65bd5e6e9ec",
              "IPY_MODEL_9bb1cc49cfa24db4bbccf61e90f2ee04",
              "IPY_MODEL_6c517bb6914b41a1a0fdb66296e4e043"
            ],
            "layout": "IPY_MODEL_1f0b6e3c82644aafa8a7e9fae28b8a72"
          }
        },
        "c2bec351358c4d88ac54e65bd5e6e9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a6d2db37f14f16951dc35f32be8104",
            "placeholder": "​",
            "style": "IPY_MODEL_46ae277f49ca4b5bbe2e1b47eb7140a0",
            "value": "Downloading: 100%"
          }
        },
        "9bb1cc49cfa24db4bbccf61e90f2ee04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad00968e696f4384ace0927f0ba9aa86",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52299a8bbe1545458a468a74b212429d",
            "value": 481
          }
        },
        "6c517bb6914b41a1a0fdb66296e4e043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a96e9e2ce9de4803a292a82c64589061",
            "placeholder": "​",
            "style": "IPY_MODEL_e9924f658ba64ad9be445a70d105e907",
            "value": " 481/481 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "1f0b6e3c82644aafa8a7e9fae28b8a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50a6d2db37f14f16951dc35f32be8104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ae277f49ca4b5bbe2e1b47eb7140a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad00968e696f4384ace0927f0ba9aa86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52299a8bbe1545458a468a74b212429d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a96e9e2ce9de4803a292a82c64589061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9924f658ba64ad9be445a70d105e907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d00222438294f619173b5e59da98c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3468bfb934df4abbacf6956eaf8e00cc",
              "IPY_MODEL_2200e32ea9564ce3bef0465d89684fae",
              "IPY_MODEL_8af6644116da4d22872c69bdd641ae56"
            ],
            "layout": "IPY_MODEL_3e5e41bd17b04f499765ce4f5a7119dd"
          }
        },
        "3468bfb934df4abbacf6956eaf8e00cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7f3b24ed052450398944309e91c2cec",
            "placeholder": "​",
            "style": "IPY_MODEL_30c17a76381c4b7fb51afe106559cb00",
            "value": "Downloading: 100%"
          }
        },
        "2200e32ea9564ce3bef0465d89684fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3159e1eca56842b59158bcb0cc7e7909",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45711ca485524c85abc75439eb5a2412",
            "value": 501200538
          }
        },
        "8af6644116da4d22872c69bdd641ae56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f626a3d3db2c412789caecbe90032af7",
            "placeholder": "​",
            "style": "IPY_MODEL_c6015fae6185428d8e9147d1109d1c4f",
            "value": " 501M/501M [00:15&lt;00:00, 37.3MB/s]"
          }
        },
        "3e5e41bd17b04f499765ce4f5a7119dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f3b24ed052450398944309e91c2cec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c17a76381c4b7fb51afe106559cb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3159e1eca56842b59158bcb0cc7e7909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45711ca485524c85abc75439eb5a2412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f626a3d3db2c412789caecbe90032af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6015fae6185428d8e9147d1109d1c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}